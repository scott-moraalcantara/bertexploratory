{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a pre-trained sentiment analysis pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9989564418792725}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "# the classifier will pick DistilBERT by default.\n",
    "text = 'I love using BERT for natural language processing tasks!'\n",
    "\n",
    "#prediction\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition with Finetuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-LOC', 'score': 0.99533033, 'index': 1, 'word': 'Toronto', 'start': 0, 'end': 7}\n",
      "{'entity': 'I-LOC', 'score': 0.998968, 'index': 3, 'word': 'New', 'start': 11, 'end': 14}\n",
      "{'entity': 'I-LOC', 'score': 0.9478587, 'index': 4, 'word': '-', 'start': 14, 'end': 15}\n",
      "{'entity': 'I-LOC', 'score': 0.9983878, 'index': 5, 'word': 'York', 'start': 15, 'end': 19}\n"
     ]
    }
   ],
   "source": [
    "# loading a pre-trained Ner pipeline, finetuned model by dbmdz.\n",
    "ner = pipeline('ner', model = 'dbmdz/bert-large-cased-finetuned-conll03-english')\n",
    "text = 'Toronto to New-York with 8 hour long drive.'\n",
    "\n",
    "#named entities\n",
    "entities = ner(text)\n",
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answer with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9966843128204346, 'start': 0, 'end': 7, 'answer': 'Toronto'}\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained question-answering pipeline, where distilbert answers a question based \n",
    "# on given context.\n",
    "\n",
    "qa = pipeline('question-answering',device=0)\n",
    "# context and question\n",
    "context = \"Toronto won against Montreal in the hockey game\"\n",
    "question = \"Who defeated Montreal in the hockey game?\"\n",
    "\n",
    "# answer\n",
    "answer = qa({'context': context, 'question': question})\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a574bbff0e6b10d854b95c9eda83fab3c2cdb76b40984feca762b0cd3c02cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
